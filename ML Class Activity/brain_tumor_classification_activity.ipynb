{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13527bbd-ad97-4ebd-a0a6-8d6d87f3b700",
   "metadata": {},
   "source": [
    "# **Solution: Brain Tumor MRI Classification - Simplified Class Activity**\n",
    "#### **Overview**\n",
    "This Jupyter Notebook guides students step by step on how to:\n",
    "1. Import libraries\n",
    "2. Download the dataset.\n",
    "3. Load a **pre-trained model** for brain tumor classification.\n",
    "4. Preprocess MRI images.\n",
    "5. Make predictions using the model.\n",
    "6. Visualize the machine learning workflow.\n",
    "\n",
    "---\n",
    "\n",
    "Credit/ Licenbse: This notebook was adapted from the work of MD.FARHAD REZA at Kaggle. A version of this Notebook has been released under the Apache 2.0 open source license."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1e3d5a-3694-4db5-b004-f9d4d9cc3ab6",
   "metadata": {},
   "source": [
    "## **üîπ Step 1: Import Libraries**\n",
    "Note: -\n",
    "1. Kagglehub is used to extract the preexisting data\n",
    "2. Tensorflow and Sklearn are one of the most common machine learning packages. Another, one is Pytorch.\n",
    "3. For simplicity, I have places some pre-made functions in the module \"brain_tumor_utils.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c576ff28-1707-45f6-9e28-d18f6c3aa6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kagglehub\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b94f27e-169b-41fd-b602-81afe2dc82f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import kagglehub\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from brain_tumor_utils import  train_df, test_df, build_model, predict, get_preprocessed_data, plot_one_image_per_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8360bdfd-3ff4-49e4-9332-aa54a6a7ca0e",
   "metadata": {},
   "source": [
    "## **üîπ Step 2: Download and Visualize the Dataset**\n",
    "\n",
    "### 2.1 Download the existing data \n",
    "\n",
    "We'll use kagglehub to automatically download the latest version of the dataset. Here is the link: https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5eb7b4-2ee9-4a77-8789-1818ef62f314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download latest version of the dataset\n",
    "path = kagglehub.dataset_download(\"masoudnickparvar/brain-tumor-mri-dataset\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5e6f84-d177-4f5f-8d4e-7cf9f55bbd79",
   "metadata": {},
   "source": [
    "### 2.2 Training and Testing Data\n",
    "\n",
    "The data is divided into two folders. Training and Testing. We will use training to train the model and then later test it using new images from the testing folder. This way its a true test of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcbae5b-7929-4512-8ed2-b9a682bcf4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading training and testing data\n",
    "tr_df = train_df(path + '/Training')\n",
    "ts_df = test_df(path + '/Testing')\n",
    "\n",
    "print(tr_df.head())\n",
    "print(ts_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6cb8f9-5481-4489-8f24-3967b78e6058",
   "metadata": {},
   "source": [
    "### 2.3 Visualizing the data\n",
    "\n",
    "Let's check what kind of images we have! The plot will show you how many images are available for each kind of tumor. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fb50e8-119a-49ec-9d56-c706feab9e85",
   "metadata": {},
   "source": [
    "## Class Activity #1 - Visualize the given data\n",
    "\n",
    "From the previous step, you have seen the structure of tr_df and ts_df. These DataFrames contain two columns:\n",
    "1. ‚ÄúClass Path‚Äù ‚Äì provides the file path to the patient‚Äôs MRI image.\n",
    "2. ‚ÄúClass‚Äù ‚Äì indicates the type of tumor.\n",
    "\n",
    "We will use these DataFrames to create a bar graph that shows the number of images available for each tumor class. Your task is to complete the missing code to count the number of images per class. Replace ??? with the correct Pandas function to count the occurrences of each tumor class.\n",
    "\n",
    "üí° Hints\n",
    "1. Use value_counts() on the \"Class\" column to get the counts.\n",
    "2. .index gives the class labels.\n",
    "3. .values gives the counts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2980297e-63c8-49a6-a1bf-4a67c82a6ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences of each class in training data\n",
    "train_counts = ???  # Fill in the missing code\n",
    "train_classes = ???  # Fill in the missing code\n",
    "print(train_counts)\n",
    "print(train_classes)\n",
    "\n",
    "# Count occurrences of each class in testing data\n",
    "test_counts = ??? # Fill in the missing code\n",
    "test_classes = ???  # Fill in the missing code\n",
    "print(test_counts)\n",
    "print(test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57fb60c-d4c8-49be-bfb8-cc23dfeea8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
    "\n",
    "# Training Data Class Distribution\n",
    "axes[0].barh(train_classes, train_counts, color='cornflowerblue')\n",
    "axes[0].set_title('Training - Count of images in each class')\n",
    "axes[0].set_xlabel('Count')\n",
    "axes[0].set_ylabel('Class')\n",
    "\n",
    "# Add labels on bars\n",
    "for index, value in enumerate(train_counts):\n",
    "    axes[0].text(value, index, str(value), va='center')\n",
    "\n",
    "# Testing Data Class Distribution\n",
    "axes[1].barh(test_classes, test_counts, color='darkorange')\n",
    "axes[1].set_title('Testing - Count of images in each class')\n",
    "axes[1].set_xlabel('Count')\n",
    "axes[1].set_ylabel('Class')\n",
    "\n",
    "# Add labels on bars\n",
    "for index, value in enumerate(test_counts):\n",
    "    axes[1].text(value, index, str(value), va='center')\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ef664a-2e8b-4574-a5f9-95cf53c23653",
   "metadata": {},
   "source": [
    "### 2.4 Spilt the testing data so we can have testing and validation dataset\n",
    "\n",
    "In machine learning, splitting the dataset is essential to evaluate the model‚Äôs performance and ensure it generalizes well to new data. The reason for splitting ts_df into valid_df and ts_df again is to create a validation set if one is missing.\n",
    "\n",
    "Note:-\n",
    "1. Training Set (tr_df) ‚Üí Used to train the model.\n",
    "2. Validation Set (valid_df) ‚Üí Used to tune the model and prevent overfitting.\n",
    "3. Test Set (ts_df) ‚Üí Used to evaluate final model performance on unseen data.\n",
    "\n",
    "Explanation of Parameters: - \n",
    "1. ts_df ‚Üí The original dataset that we want to split.\n",
    "2. train_size=0.5 ‚Üí 50% of ts_df will be used for validation (valid_df), and the remaining 50% stays in ts_df as the test set.\n",
    "3. random_state=20 ‚Üí Ensures the split is reproducible (i.e., every time you run it, you get the same split).\n",
    "4. stratify=ts_df['Class'] ‚Üí Ensures the split preserves the class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6571f0ca-4842-4a10-968f-324f7bb85d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ts_df.shape) # original number of images in test dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bff9041-a0b0-4be6-8fc4-b8d48fe3b1d9",
   "metadata": {},
   "source": [
    "We have created a function that spilts the testing dataset into validation and testing data. \n",
    "\n",
    "Note: Everytime you call this function it will spilt the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845905ee-c2ac-481d-a526-182e219ed507",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df, ts_df = train_test_split(ts_df, train_size=0.5, random_state=20, stratify=ts_df['Class'])\n",
    "\n",
    "print(valid_df.shape)\n",
    "print(ts_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deabc19-47f4-44a8-bbe0-bf9ce50af702",
   "metadata": {},
   "source": [
    "### 2.5 Preprocessing the data\n",
    "\n",
    "If you check out the source of the dataset: https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset/data, you will see that the images are not of the same size. Hence, we will rescale them to make them all of same size. We have already create a function in \"brain_tumor_utlis.py\". If you are curious, take a look and see how it works. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1ee9dc-6991-420a-89de-1312e7202c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_gen, valid_gen, ts_gen = get_preprocessed_data(tr_df, valid_df, ts_df, batch_size=32, img_size=(299, 299))\n",
    "\n",
    "print(\"\")\n",
    "print(tr_gen)\n",
    "print(\"\")\n",
    "print(f\"Total Samples: {tr_gen.n}\")\n",
    "print(f\"Number of Classes: {len(tr_gen.class_indices)}\")\n",
    "print(f\"Class Indices: {tr_gen.class_indices}\")  # Mapping of class names to indices\n",
    "print(f\"Image Shape: {tr_gen.image_shape}\")  # Expected image size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb1e2f3-33f6-4083-8bb2-96e184d25b8f",
   "metadata": {},
   "source": [
    "## Class Activity #2 - Visualize MRI images from different tumor or no-tumor.\n",
    "\n",
    "In groups of 2-3, discuss the plot_one_image_per_class function (stored in \"brain_tumor_utils.py\" module). This function takes a data structure (like tr_gen), which holds the preprocessed training image dataset. \n",
    "\n",
    "Task: Call this function with an appropriate input argument to display images from preprocessed training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fd65ae-bd1a-413c-bb74-305a676d4e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code below. Call the function with the right input!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574708bf-bfc0-4d06-8d04-07d49f92c07f",
   "metadata": {},
   "source": [
    "## **üîπ Step 3: Define a model**\n",
    "\n",
    "Note: I have already trained this model, as it takes several hours to run. The training code is commented out, but it demonstrates how to define a neural network called ResNet, a widely used architecture in image recognition.\n",
    "\n",
    "ResNet (Residual Network) is known for its deep structure and skip connections, which help prevent vanishing gradient issues and improve accuracy in deep learning models. It is commonly used for medical imaging, object detection, and other vision tasks. It's okay, if you don't fully know about this model, it's a little complex. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43341a01-9132-4b04-8ba3-59a4ac51dac1",
   "metadata": {},
   "source": [
    "## Step 3.1 - Defining the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd28ca1-48b4-40d1-b99b-f271002f41c2",
   "metadata": {},
   "source": [
    "Below, you will see what all different layers containing or neurons are used in the model. \n",
    "\n",
    "Neural networks use different types of layers, each serving a specific function. Some extract features (like ResNet50), some transform data (like Flatten), and others help prevent overfitting (like Dropout), all working together to improve learning and predictions.\n",
    "\n",
    "For now, don‚Äôt worry about the many names you see‚Äîwe won‚Äôt dive into each one. These details go beyond the scope of this class. \n",
    "\n",
    "But, we you look at the \"build_model\" function inside the \"brain_tumor_utils.py\", you will see that we are using ResNet50 model. It's one of the commmonly used models in image recognition tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb24865-19c8-4432-a66e-7ded805e04ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet Model\n",
    "model = build_model(img_shape=(299, 299, 3), learning_rate=0.001)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ae3f26-4553-41af-8d4b-34da6f1a1190",
   "metadata": {},
   "source": [
    "## Step 3.2 - Training and saving the model\n",
    "\n",
    "We have saved the trained model parameters (in file \"training_history.pkl\" and \"brain_tumor_model.h5\") so we can use it directly during the class without waiting for training to complete. \n",
    "\n",
    "***DO NOT COMMENT OUT the BELOW CODE! IT WILL START TRAINING THE MODEL AND WILL TAKE HOURS TO COMPLETE. ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cb73f9-4601-4890-bfe1-6d9e90426f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define paths\n",
    "# model_path = \"brain_tumor_model.h5\"\n",
    "# history_path = \"training_history.pkl\"\n",
    "# csv_path = \"training_history.csv\"\n",
    "\n",
    "# # Define ModelCheckpoint to save model after each epoch\n",
    "# checkpoint = ModelCheckpoint(\n",
    "#     model_path,\n",
    "#     monitor=\"val_loss\",\n",
    "#     save_best_only=False,\n",
    "#     save_weights_only=False,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# # Define CSVLogger to save training history after every epoch\n",
    "# csv_logger = CSVLogger(csv_path, append=True)\n",
    "\n",
    "# # Train the model with checkpointing and logging\n",
    "# hist = model.fit(\n",
    "#     tr_gen,\n",
    "#     epochs=10,\n",
    "#     validation_data=valid_gen,\n",
    "#     shuffle=False,\n",
    "#     callbacks=[checkpoint, csv_logger]  # Save model & history\n",
    "# )\n",
    "\n",
    "# # Save training history separately\n",
    "# with open(history_path, \"wb\") as f:\n",
    "#     pickle.dump(hist.history, f)\n",
    "\n",
    "# print(\"Training complete! Model and history saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a33962-a7d4-4ab3-a096-f7f4ea374f7a",
   "metadata": {},
   "source": [
    "## Step 3.3 - Loading the trained model and Visualizing the performance of the model \n",
    "\n",
    "There are two kind of losses: -\n",
    "1. Training Loss üîÑ - The error (or loss) calculated during training on the training dataset.\n",
    "2. Validation Loss üßê - The error calculated on a separate validation dataset that the model has not seen during training.\n",
    "\n",
    "Epochs refer to the number of times a neural network sees the entire training dataset during training. One epoch means the model has gone through all the training data once, adjusting its weights to improve predictions. More epochs allow the model to learn better, but too many can lead to overfitting. \n",
    "\n",
    "It‚Äôs like repeating a lesson to a child multiple times until they fully understand and remember it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682a276e-6b13-44ce-ba8a-e2d0959793fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "model = load_model(\"brain_tumor_model.h5\")\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Load training history\n",
    "history_path = \"training_history.pkl\"\n",
    "\n",
    "try:\n",
    "    with open(history_path, \"rb\") as f:\n",
    "        history = pickle.load(f)\n",
    "    print(\"Training history loaded!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"No training history found. Consider re-training.\")\n",
    "\n",
    "# Now 'history' contains training metrics\n",
    "if 'history' in locals():\n",
    "    tr_acc = history['accuracy']\n",
    "    tr_loss = history['loss']\n",
    "    tr_per = history.get('precision', [])\n",
    "    tr_recall = history.get('recall', [])\n",
    "    val_acc = history['val_accuracy']\n",
    "    val_loss = history['val_loss']\n",
    "    val_per = history.get('val_precision', [])\n",
    "    val_recall = history.get('val_recall', [])\n",
    "\n",
    "    # Visualizing the metrics\n",
    "    Epochs = [i + 1 for i in range(len(tr_acc))]\n",
    "\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(Epochs, tr_loss, 'r', label='Training loss')\n",
    "    plt.plot(Epochs, val_loss, 'g', label='Validation loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')  # X-axis label\n",
    "    plt.ylabel('Loss/ Error')  # Y-axis label\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9a2b20-ba03-4eca-acdf-bf545259fd34",
   "metadata": {},
   "source": [
    "## Test the model with new images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f14c9f-0d59-415b-bdae-17613d0e8486",
   "metadata": {},
   "source": [
    "## Class Activity #3 - Test the models for new images that it hasn't seen before.\n",
    "\n",
    "1. Go to the original database website: https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset/data\n",
    "2. Scroll down a bit and you will see \"Testing\" with four directories. These images are not used to train the model.\n",
    "3. Copy paste the name of the image from any of these directory noting down which directory and change the below patient variables to give that image to the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2b8366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some example image locations:\n",
    "# patient1 = \"glioma/Te-glTr_0005.jpg\"\n",
    "# patient2 = \"meningioma/Te-meTr_0003.jpg\"\n",
    "# patient3 = 'pituitary/Te-piTr_0003.jpg'\n",
    "\n",
    "patient = \"glioma/Te-glTr_0009.jpg\"\n",
    "predict(path + '/Testing/' + patient, ts_gen.class_indices, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b524074-f3ff-434e-85d0-47f7b5853fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
